"""
ë²¡í„° DBì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í…ŒìŠ¤íŠ¸ ì½”ë“œ
ì§ì ‘ ì •ì˜í•œ ì¿¼ë¦¬ ë¬¸ì¥ìœ¼ë¡œ ì„ë² ë”© ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
"""
from typing import List, Dict

from pymilvus import (
    connections,
    Collection,
)
from sentence_transformers import SentenceTransformer
import torch


# ì„¤ì • (insert2db.pyì™€ ë™ì¼)
MILVUS_HOST = "192.168.50.20"
MILVUS_PORT = "19530"
COLLECTION_NAME = "legal_documents"
EMBEDDING_MODEL = "google/embeddinggemma-300m"
DIMENSION = 768
USE_CPU = False  # Trueë¡œ ì„¤ì •í•˜ë©´ CPU ì‚¬ìš©

# í…ŒìŠ¤íŠ¸í•  ì¿¼ë¦¬ ë¬¸ì¥ (ì§ì ‘ ì •ì˜)
TEST_QUERIES = [
    "ë™ì—… ì¡°í•© í•´ì‚° í›„, ì¼ë°© ì²­ì‚°ì¸ì´ ì²­ì‚° ì ˆì°¨ì— ë¹„í˜‘ì¡°í•œë‹¤ëŠ” ì´ìœ ë¡œ ë‹¤ë¥¸ ì²­ì‚°ì¸ì´ ê·¸ì— ëŒ€í•œ ì§ë¬´ì§‘í–‰ì •ì§€ ê°€ì²˜ë¶„ì„ ì‹ ì²­í•œ ì‚¬ê±´ì…ë‹ˆë‹¤. ë²•ì›ì€ ë¯¼ë²•ìƒ 'ì¡°í•©'ì˜ ì²­ì‚°ì¸ì€ ë²•ì¸ì˜ ì²­ì‚°ì¸ê³¼ ë‹¬ë¦¬ ë²•ì›ì— í•´ì„ì„ ì²­êµ¬í•  ë²•ì  ê·¼ê±°ê°€ ì—†ìœ¼ë¯€ë¡œ, í•´ë‹¹ ê°€ì²˜ë¶„ ì‹ ì²­ì€ ë¶€ì ë²•í•˜ë‹¤ê³  ë³´ì•„ ê°í•˜í–ˆìŠµë‹ˆë‹¤.",
    "ë°°ë‹¹ìš”êµ¬ì‹ ì²­ì„œë¼ëŠ” ì œëª©ì´ë‚˜ ì¸ì§€ë¥¼ ì²©ë¶€í•˜ì§€ ì•Šê³  ì±„ê¶Œê³„ì‚°ì„œë§Œ ì œì¶œí–ˆì–´ë„, ì±„ê¶Œì˜ ì›ì¸ê³¼ ìˆ˜ì•¡ì´ ëª…ì‹œë˜ì—ˆë‹¤ë©´ ì ë²•í•œ ë°°ë‹¹ìš”êµ¬ë¡œ ë³´ì•„ì•¼ í•œë‹¤ê³  íŒì‹œí–ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë¶€ë™ì‚° ì••ë¥˜ íš¨ë ¥ì´ ë°œìƒí•œ ì´í›„ì— ê·¼ì €ë‹¹ê¶Œ ë“±ê¸°ë¥¼ ë§ˆì¹œ ë‹´ë³´ë¬¼ê¶Œìë„ ë³„ë„ì˜ ê°€ì••ë¥˜ ì ˆì°¨ ì—†ì´, ì••ë¥˜ì±„ê¶Œìì™€ ì±„ê¶Œì•¡ì— ë¹„ë¡€í•˜ì—¬ í‰ë“±í•˜ê²Œ ë°°ë‹¹ë°›ì„ ìˆ˜ ìˆë‹¤",

]


def connect_to_milvus():
    """Milvusì— ì—°ê²°í•©ë‹ˆë‹¤."""
    try:
        connections.connect(
            alias="default",
            host=MILVUS_HOST,
            port=MILVUS_PORT
        )
        print(f"âœ“ Milvusì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤: {MILVUS_HOST}:{MILVUS_PORT}")
    except Exception as e:
        print(f"âœ— Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
        raise


def search_similar_chunks(collection: Collection, query_embedding: List[float], top_k: int = 5) -> List[Dict]:
    """
    Milvusì—ì„œ ìœ ì‚¬í•œ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        collection: Milvus ì»¬ë ‰ì…˜ ê°ì²´
        query_embedding: ê²€ìƒ‰ ì¿¼ë¦¬ ì„ë² ë”© ë²¡í„°
        top_k: ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜
        
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    # ì»¬ë ‰ì…˜ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¡œë“œ
    if not collection.has_index():
        print("âš ï¸  ì»¬ë ‰ì…˜ì— ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    try:
        collection.load()
    except Exception:
        pass
    
    # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
    search_params = {
        "metric_type": "L2",
        "params": {"nprobe": 10}
    }
    
    # ê²€ìƒ‰ ìˆ˜í–‰
    results = collection.search(
        data=[query_embedding],
        anns_field="embedding",
        param=search_params,
        limit=top_k,
        output_fields=["file_path", "category", "name", "chunk_text", "chunk_index"]
    )
    
    # ê²°ê³¼ íŒŒì‹± (ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì €ì¥)
    search_results = []
    if results and len(results) > 0:
        for hit in results[0]:
            # ì›ë³¸ ë°ì´í„° ê·¸ëŒ€ë¡œ ì €ì¥
            search_results.append({
                "id": hit.id,
                "distance": hit.distance,
                "file_path": hit.entity.get("file_path", ""),
                "category": hit.entity.get("category", ""),
                "name": hit.entity.get("name", ""),
                "chunk_text": hit.entity.get("chunk_text", ""),
                "chunk_index": hit.entity.get("chunk_index", -1),
            })
    
    return search_results


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("ë²¡í„° DB ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 80)
    
    # 1. Milvus ì—°ê²°
    print("\n[1/4] Milvus ì—°ê²° ì¤‘...")
    connect_to_milvus()
    
    # 2. ì»¬ë ‰ì…˜ ë¡œë“œ
    print("\n[2/4] ì»¬ë ‰ì…˜ ë¡œë“œ ì¤‘...")
    try:
        collection = Collection(COLLECTION_NAME)
        collection.load()
        print(f"âœ“ ì»¬ë ‰ì…˜ '{COLLECTION_NAME}' ë¡œë“œ ì™„ë£Œ")
        print(f"  ì´ ë²¡í„° ê°œìˆ˜: {collection.num_entities:,}ê°œ")
    except Exception as e:
        print(f"âœ— ì»¬ë ‰ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    print("\n[3/4] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
    print(f"ëª¨ë¸: {EMBEDDING_MODEL}")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if USE_CPU:
        device = 'cpu'
        print("âš ï¸  CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤")
    else:
        if torch.backends.mps.is_available():
            device = 'mps'
            print("âœ“ MPS (Apple Silicon GPU) ì‚¬ìš©")
        else:
            device = 'cpu'
            print("âš ï¸  CPU ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤ (MPS ì‚¬ìš© ë¶ˆê°€)")
    
    model = SentenceTransformer(EMBEDDING_MODEL, device=device)
    print("âœ“ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    # 4. ì§ì ‘ ì •ì˜í•œ ì¿¼ë¦¬ ë¬¸ì¥ìœ¼ë¡œ ê²€ìƒ‰
    print("\n[4/4] ì¿¼ë¦¬ ë¬¸ì¥ìœ¼ë¡œ ê²€ìƒ‰ ì¤‘...")
    print("=" * 80)
    
    test_cases = []
    
    for idx, query_sentence in enumerate(TEST_QUERIES, 1):
        print(f"\n[ì¿¼ë¦¬ {idx}]")
        print(f"  ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ë¬¸ì¥:")
        print(f"  {query_sentence.replace(chr(10), ' ').replace(chr(13), ' ')}")
        
        # ì„ë² ë”© ìƒì„±
        print(f"  â³ ì„ë² ë”© ìƒì„± ì¤‘...")
        query_embedding = model.encode(
            query_sentence,
            show_progress_bar=False,
            convert_to_numpy=True
        ).tolist()
        
        # ë²¡í„° ê²€ìƒ‰
        print(f"  â³ ë²¡í„° ê²€ìƒ‰ ì¤‘...")
        search_results = search_similar_chunks(collection, query_embedding, top_k=5)
        
        if not search_results:
            print(f"  âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            continue
        
        # ê²°ê³¼ ì €ì¥
        test_cases.append({
            "query_sentence": query_sentence,
            "search_results": search_results
        })
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n  ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„ 5ê°œ):")
        print(f"  {'-' * 76}")
        for result_idx, result in enumerate(search_results, 1):
            print(f"\n  [{result_idx}] ê±°ë¦¬: {result['distance']:.4f}")
            print(f"      íŒŒì¼: {result['file_path']}")
            print(f"      ë¬¸ì„œëª…: {result['name']}")
            print(f"      ì²­í¬ ì¸ë±ìŠ¤: {result['chunk_index']}")
            chunk_text = result['chunk_text'].replace(chr(10), ' ').replace(chr(13), ' ')
            print(f"      ì²­í¬ ë‚´ìš©: {chunk_text}")
    
    # ì „ì²´ ìš”ì•½ ì¶œë ¥
    print("\n" + "=" * 80)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ ìš”ì•½")
    print("=" * 80)
    print(f"ì´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤: {len(test_cases)}ê°œ")
    for idx, case in enumerate(test_cases, 1):
        print(f"\n[í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {idx}]")
        query_text = case['query_sentence'].replace(chr(10), ' ').replace(chr(13), ' ')
        print(f"  ì¿¼ë¦¬: {query_text}")
        print(f"  ê²€ìƒ‰ ê²°ê³¼: {len(case['search_results'])}ê°œ")


if __name__ == "__main__":
    main()

